The goal of this project is to build and test a deep learning model that can accurately identify
hand gestures representing the ASL alphabet. The model will also recognize gestures for
SPACE, DELETE, and NOTHING, making it more useful in real-time conversations. This
project aims to help people who are hearing-impaired communicate more easily with those
who do not know sign language.

References :
Dataset: https://www.kaggle.com/datasets/grassknoted/asl-alphabet/data
